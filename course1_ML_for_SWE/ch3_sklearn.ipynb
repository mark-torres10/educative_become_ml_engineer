{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import RobustScaler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are using a variety of transformers that are available in sklearn. They all have similar structures \n",
    "and implement a fit_transform() method. These transformers allow us to perform a variety of data \n",
    "preprocessing steps on our data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Standardizing Data\n",
    "\n",
    "For each data value, x, we subtract the overall mean of the data, μ, then divide by the overall standard deviation, \n",
    "σ. The new value, z, represents the standardized data value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([[2100,   10,  800],\n",
      "       [2500,   11,  850],\n",
      "       [1800,   10,  760],\n",
      "       [2000,   12,  800],\n",
      "       [2300,   11,  810]])\n",
      "\n",
      "array([[-0.16552118, -1.06904497, -0.1393466 ],\n",
      "       [ 1.4896906 ,  0.26726124,  1.60248593],\n",
      "       [-1.40693001, -1.06904497, -1.53281263],\n",
      "       [-0.57932412,  1.60356745, -0.1393466 ],\n",
      "       [ 0.66208471,  0.26726124,  0.2090199 ]])\n",
      "\n",
      "array([ 0., -0.,  0.])\n",
      "\n",
      "array([1., 1., 1.])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# standardizing data\n",
    "pizza_data = np.array([[2100,   10,  800],\n",
    "                       [2500,   11,  850],\n",
    "                       [1800,   10,  760],\n",
    "                       [2000,   12,  800],\n",
    "                       [2300,   11,  810]])\n",
    "\n",
    "\n",
    "# Newline to separate print statements\n",
    "print('{}\\n'.format(repr(pizza_data)))\n",
    "\n",
    "# Standardizing each column of pizza_data\n",
    "col_standardized = scale(pizza_data)\n",
    "print('{}\\n'.format(repr(col_standardized)))\n",
    "\n",
    "# Column means (rounded to nearest thousandth)\n",
    "col_means = col_standardized.mean(axis=0).round(decimals=3)\n",
    "print('{}\\n'.format(repr(col_means)))\n",
    "\n",
    "# Column standard deviations\n",
    "col_stds = col_standardized.std(axis=0)\n",
    "print('{}\\n'.format(repr(col_stds)))\n",
    "\n",
    "\n",
    "# we normally do separate standardizations for each column (so that each column is a standardized version of itself)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also compress data to a particular range of values (e.g., make every data point be from [0, 1] or some other custom range). \n",
    "\n",
    "The formula for scaling based on a range is a two-step process. For a given data value, x, we first compute the proportion of the value with respect to the min and max of the data dmin and dmax, respectively).\n",
    "\n",
    "$x_{prop} = \\frac{x - min}{max - min}$ \n",
    "\n",
    "Now x takes values from 0 (if x = min) to 1 (if x = max)\n",
    "\n",
    "Now, we then apply this [0, 1] scale to any range that we'd like, using the following procedure:\n",
    "\n",
    "$x_{scale} = x_{prop} * (max - min) + min$\n",
    "\n",
    "Sklearn provides a variety of $transformers$, modules that allow us to transform the data\n",
    "The MinMaxScaler() performs the range compression that we did above. By default, it compresses the data to [0, 1]. \n",
    "\n",
    "We can instantiate a MinMaxScaler() object, then use its fit, transform, or fit_transform() methods on our data\n",
    "in order to return a scaled version of our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.2  3.2]\n",
      " [-0.3 -1.2]\n",
      " [ 6.5 10.1]\n",
      " [ 2.2 -8.4]]\n",
      "\n",
      "\n",
      "\n",
      "[[0.22058824 0.62702703]\n",
      " [0.         0.38918919]\n",
      " [1.         1.        ]\n",
      " [0.36764706 0.        ]]\n",
      "\n",
      "\n",
      "\n",
      "[[-0.89705882  1.13513514]\n",
      " [-2.         -0.05405405]\n",
      " [ 3.          3.        ]\n",
      " [-0.16176471 -2.        ]]\n",
      "This is the range of observations from the scaled data: [ 6.8 18.5]\n",
      "This shows that when you fit the data, the MinMaxScaler object takes in the data\n",
      "[[0.22058824 0.62702703]\n",
      " [0.         0.38918919]\n",
      " [1.         1.        ]\n",
      " [0.36764706 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "data = np.array([[ 1.2,  3.2],\n",
    "                 [-0.3, -1.2],\n",
    "                 [ 6.5, 10.1],\n",
    "                 [ 2.2, -8.4]])\n",
    "\n",
    "print(data)\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "# using default params\n",
    "scaler = MinMaxScaler()\n",
    "scaled_data = scaler.fit_transform(data)\n",
    "\n",
    "print(scaled_data)\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "# using new range\n",
    "custom_scaler = MinMaxScaler(feature_range = (-2, 3))\n",
    "custom_scaled_data = custom_scaler.fit_transform(data)\n",
    "print(custom_scaled_data)\n",
    "\n",
    "# we can also take the fit and transform functions separately. \n",
    "# the fit function operates on the MinMaxScaler object and allows it to take in a data object (presumably\n",
    "# now as an attribute, say, scaler.data, of the object?) and transform performs the actual transformation\n",
    "\n",
    "new_scaler = MinMaxScaler()\n",
    "new_scaler.fit(data) # input data\n",
    "print(\"This is the range of observations from the scaled data: {}\".format(new_scaler.data_range_))\n",
    "print(\"This shows that when you fit the data, the MinMaxScaler object takes in the data\")\n",
    "new_data_fit = new_scaler.transform(data) # seems like you still need to input the dataset\n",
    "print(new_data_fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But, when we scale, it's also important to not be affected by outliers. To do so, we can use sklearn's RobustScaler(), rather than the MinMaxScaler()\n",
    "\n",
    "Previously, we used a dataset's minimum and maximum values to scale. However, if there are outliers, these values skew our dataset. \n",
    "\n",
    "We can robustly scale the data, i.e. avoid being affected by outliers, by using use the data's median and Interquartile Range (IQR). Since the median and IQR are percentile measurements of the data (50% for median, 25% to 75% for the IQR), they are not affected by outliers. For the scaling method, we just subtract the median from each data value then scale to the IQR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.2  3.2]\n",
      " [-0.3 -1.2]\n",
      " [ 6.5 10.1]\n",
      " [ 2.2 -8.4]]\n",
      "\n",
      "\n",
      "[[-0.20408163  0.27760252]\n",
      " [-0.81632653 -0.27760252]\n",
      " [ 1.95918367  1.14826498]\n",
      " [ 0.20408163 -1.18611987]]\n"
     ]
    }
   ],
   "source": [
    "# using RobustScaler()\n",
    "# the fit method doesn't store the data. Rather, it keeps the median and quartiles that will then be used during\n",
    "# the transformation\n",
    "\n",
    "print(data)\n",
    "print(\"\\n\")\n",
    "robust_scaler = RobustScaler()\n",
    "transformed = robust_scaler.fit_transform(data)\n",
    "print(transformed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each of the scaling features above were done for individual columns. \n",
    "\n",
    "But, what if we instead wanted to standardize the values of a row? This is helpful, for example, in cases where we need all the entries in a row to add up to 1?\n",
    "\n",
    "To do so, we can normalize our data. \n",
    "\n",
    "One normalization method is L2 normalization, in which we divide each row's observations by the L2 norm of that row. \n",
    "\n",
    "Remember, a norm $L_p$ is defined as:\n",
    "\n",
    "$||X||_p = (\\sum\\limits_{i = 1}^{N} |X_i|^p)^{1/p}$\n",
    "\n",
    "In sklearn, the L2 normalization is implemented by the Normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.2  3.2]\n",
      " [-0.3 -1.2]\n",
      " [ 6.5 10.1]\n",
      " [ 2.2 -8.4]]\n",
      "\n",
      "\n",
      "array([[ 0.35112344,  0.93632918],\n",
      "       [-0.24253563, -0.9701425 ],\n",
      "       [ 0.54117832,  0.84090786],\n",
      "       [ 0.25335939, -0.96737222]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "print(data)\n",
    "print(\"\\n\")\n",
    "\n",
    "normalizer = Normalizer()\n",
    "transformed = normalizer.fit_transform(data)\n",
    "print('{}\\n'.format(repr(transformed)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also will have cases where we're missing data. How do we impute missing data?\n",
    "\n",
    "In sklearn, the SimpleImputer() transformer provides 4 common imputation methods: using the mean value, using the median value, using the most common value, and using a constant value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  2. nan  2.]\n",
      " [ 5. nan  1.  2.]\n",
      " [ 4. nan  3. nan]\n",
      " [ 5.  6.  8.  1.]\n",
      " [nan  7. nan  0.]]\n",
      "\n",
      "\n",
      "[[1.   2.   4.   2.  ]\n",
      " [5.   5.   1.   2.  ]\n",
      " [4.   5.   3.   1.25]\n",
      " [5.   6.   8.   1.  ]\n",
      " [3.75 7.   4.   0.  ]]\n",
      "\n",
      "\n",
      "[[1.  2.  3.  2. ]\n",
      " [5.  6.  1.  2. ]\n",
      " [4.  6.  3.  1.5]\n",
      " [5.  6.  8.  1. ]\n",
      " [4.5 7.  3.  0. ]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "data_missing = np.array([[ 1.,  2., np.nan,  2.],\n",
    "                         [ 5., np.nan,  1.,  2.],\n",
    "                         [ 4., np.nan,  3., np.nan],\n",
    "                         [ 5.,  6.,  8.,  1.],\n",
    "                         [np.nan,  7., np.nan,  0.]])\n",
    "\n",
    "print(data_missing)\n",
    "print(\"\\n\")\n",
    "\n",
    "impute_mean = SimpleImputer(strategy = 'mean')\n",
    "imputed_data = impute_mean.fit_transform(data_missing)\n",
    "print(imputed_data)\n",
    "print(\"\\n\")\n",
    "\n",
    "impute_median = SimpleImputer(strategy = 'median')\n",
    "imputed_median_data = impute_median.fit_transform(data_missing)\n",
    "print(imputed_median_data)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a part of our data preprocessing steps, we can also perform dimensionality reduction and reduce the number of columns in our dataset. One approach to doing this is by performing PCA. \n",
    "\n",
    "PCA extracts the principal components of the dataset, which are an uncorrelated set of latent variables that encompass most of the information from the original dataset. Using a smaller set of principal components can make it a lot easier to use the dataset in statistical or machine learning models (especially when the original dataset contains many correlated features).\n",
    "\n",
    "Like any other data transformation method, there is a PCA() transformer in sklearn. When we initialize the PCA() object, we can include an \"n_components\" keyword (default = m - 1, where m = # of features) that determines how many principal components will be a part of our analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([[-4.8600e+00,  4.6300e+00, -4.7000e-02,  0.0000e+00],\n",
      "       [-3.7990e+00, -1.3180e+00,  1.2700e-01,  0.0000e+00],\n",
      "       [-1.8630e+00, -4.2260e+00, -8.9000e-02,  0.0000e+00],\n",
      "       [ 1.0522e+01,  9.1400e-01,  9.0000e-03,  0.0000e+00]])\n",
      "\n",
      "array([[-4.8600e+00,  4.6300e+00, -4.7000e-02],\n",
      "       [-3.7990e+00, -1.3180e+00,  1.2700e-01],\n",
      "       [-1.8630e+00, -4.2260e+00, -8.9000e-02],\n",
      "       [ 1.0522e+01,  9.1400e-01,  9.0000e-03]])\n",
      "\n",
      "array([[-4.86 ,  4.63 ],\n",
      "       [-3.799, -1.318],\n",
      "       [-1.863, -4.226],\n",
      "       [10.522,  0.914]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# perform PCA on a new set of data\n",
    "new_data = np.array([[ 1.5,  3. ,  9. , -0.5,  1. ],\n",
    "                     [ 2.2,  4.3,  3.5,  0.6,  2.7],\n",
    "                     [ 3. ,  6.1,  1.1,  1.2,  4.2],\n",
    "                     [ 8. , 16. ,  7.7, -1. ,  7.1]])\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca_obj = PCA() # The value of n_component will be 4. As m is 5 and default is always m-1\n",
    "pc = pca_obj.fit_transform(new_data).round(3) # keeps 4 columns, projects data along these 4 principal components\n",
    "print('{}\\n'.format(repr(pc)))\n",
    "\n",
    "pca_obj = PCA(n_components=3)\n",
    "pc = pca_obj.fit_transform(new_data).round(3) # keeps 3 columns, projects data along these three columns\n",
    "print('{}\\n'.format(repr(pc)))\n",
    "\n",
    "pca_obj = PCA(n_components=2)\n",
    "pc = pca_obj.fit_transform(new_data).round(3) # keeps 2 columns, projects data along these two columns\n",
    "print('{}\\n'.format(repr(pc)))\n",
    "\n",
    "#NOTE: each row(observation) has only 2, 3, or 4 values, in contrast to 5 from before. These\n",
    "# values are its projections onto the principal components (e.g., entry [0, 0] is the first observation's \n",
    "# projection onto the first axis, or the first principal component, while entry [0, 2] is the first observation's\n",
    "# projection onto the third axis, or the third principal component)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's look at an example of separating data by class:\n",
    "\n",
    "In this example, we are looking at tumors (malignant vs. benign). We can project the data along two principal components, get our transformed data after we project it ontho these two components, then graph them. Given the nature of this particular data, we will see that the data likely clusters nicely around the principal component, since we do see natural clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2.654e-01, 4.601e-01,\n",
      "        1.189e-01],\n",
      "       [2.057e+01, 1.777e+01, 1.329e+02, ..., 1.860e-01, 2.750e-01,\n",
      "        8.902e-02],\n",
      "       [1.969e+01, 2.125e+01, 1.300e+02, ..., 2.430e-01, 3.613e-01,\n",
      "        8.758e-02],\n",
      "       ...,\n",
      "       [1.660e+01, 2.808e+01, 1.083e+02, ..., 1.418e-01, 2.218e-01,\n",
      "        7.820e-02],\n",
      "       [2.060e+01, 2.933e+01, 1.401e+02, ..., 2.650e-01, 4.087e-01,\n",
      "        1.240e-01],\n",
      "       [7.760e+00, 2.454e+01, 4.792e+01, ..., 0.000e+00, 2.871e-01,\n",
      "        7.039e-02]])\n",
      "\n",
      "Data shape: (569, 30)\n",
      "\n",
      "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
      "       1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
      "       1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
      "       0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
      "       1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
      "       0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
      "       1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
      "       1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
      "       0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
      "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
      "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
      "       1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
      "       1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
      "       1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1])\n",
      "\n",
      "Labels shape: (569,)\n",
      "\n",
      "['malignant', 'benign']\n",
      "\n",
      "Malignant shape: (212, 30)\n",
      "\n",
      "Benign shape: (357, 30)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "bc = load_breast_cancer()\n",
    "print('{}\\n'.format(repr(bc.data)))\n",
    "print('Data shape: {}\\n'.format(bc.data.shape))\n",
    "\n",
    "# Class labels\n",
    "print('{}\\n'.format(repr(bc.target)))\n",
    "print('Labels shape: {}\\n'.format(bc.target.shape))\n",
    "\n",
    "# Label names\n",
    "print('{}\\n'.format(list(bc.target_names)))\n",
    "\n",
    "malignant = bc.data[bc.target == 0]\n",
    "print('Malignant shape: {}\\n'.format(malignant.shape))\n",
    "\n",
    "benign = bc.data[bc.target == 1]\n",
    "print('Benign shape: {}\\n'.format(benign.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label_info(component_data, labels,class_label, label_names):\n",
    "    \"\"\"\n",
    "        Extracts the label from the observation. In this case, used on data that's\n",
    "        already been projected onto the principal component\n",
    "    \"\"\"\n",
    "    label_name = label_names[class_label]\n",
    "    label_data = component_data[labels == class_label]\n",
    "    return (label_name, label_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_data(component_data, labels,label_names):\n",
    "    separated_data = []\n",
    "    for class_label in range(len(label_names)):\n",
    "        separated_data.append(get_label_info(\n",
    "            component_data, labels, class_label, label_names))\n",
    "    return separated_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.decomposition import PCA\n",
    "bc = load_breast_cancer()\n",
    "pca_obj = PCA(n_components=2)\n",
    "component_data = pca_obj.fit_transform(bc.data)\n",
    "labels = bc.target\n",
    "label_names = bc.target_names\n",
    "# Using the completed separate_data function\n",
    "separated_data = separate_data(component_data,\n",
    "                               labels, label_names)\n",
    "\n",
    "# Plotting the data\n",
    "import matplotlib.pyplot as plt\n",
    "for label_name, label_data in separated_data:\n",
    "    col1 = label_data[:, 0]  # 1st column (1st pr. comp.)\n",
    "    col2 = label_data[:, 1]  # 2nd column (2nd pr. comp.)\n",
    "    plt.scatter(col1, col2, label=label_name) # scatterplot\n",
    "plt.legend()  # adds legend to plot\n",
    "plt.title('Breast Cancer Dataset PCA Plot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
